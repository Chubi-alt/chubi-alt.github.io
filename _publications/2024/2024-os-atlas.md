---
title:          "OS-ATLAS: A Foundation Action Model For Generalist GUI Agents"
date:           2024-10-30
selected:       true
pub:            "ICLR 2025"
pub_last:       '<span class="badge badge-pill badge-publication badge-success">Spotlight</span>'
pub_date:       "2025"
abstract: >-
  Existing efforts in building GUI agents heavily rely on the availability of robust commercial Vision-Language Models (VLMs) such as GPT-4o and GeminiProVision. Practitioners are often reluctant to use open-source VLMs due to their significant performance lag compared to their closed-source counterparts, particularly in GUI grounding and Out-Of-Distribution (OOD) scenarios. To facilitate future research in this area, we developed OS-Atlas â€”a foundational GUI action model that excels at GUI grounding and OOD agentic tasks through innovations in both data and modeling. We have invested significant engineering effort in developing an open-source toolkit for synthesizing GUI grounding data across multiple platforms, including Windows, Linux, MacOS, Android, and the web. Leveraging this toolkit, we are releasing the largest open-source cross-platform GUI grounding corpus to date, which contains over 13 million GUI elements. This dataset, combined with innovations in model training, provides a solid foundation for OS-Atlas to understand GUI screenshots and generalize to unseen interfaces. Through extensive evaluation across six benchmarks spanning three different platforms (mobile, desktop, and web), OS-Atlas demonstrates significant performance improvements over previous state-of-the-art models. Our evaluation also uncovers valuable insights into continuously improving and scaling the agentic capabilities of open-source VLMs.
cover:          /assets/images/covers/cover1.jpg
authors:
- Ian Wang*
- Robert White*
- John Doe
- Charles Green (Stanford)
links:
  Website: https://osatlas.github.io/
  Paper: https://arxiv.org/abs/2410.23218
  Code: https://github.com/OS-Copilot/OS-Atlas
---
